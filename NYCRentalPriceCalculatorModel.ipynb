{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ff41c3",
   "metadata": {},
   "source": [
    "# Rental Price Calculator Model\n",
    "\n",
    "## Data\n",
    "\n",
    "We load the data that we have cleaned up. This is already separated into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b6a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb685ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/clean_rent_data_post_desc_train.csv\")\n",
    "test_df = pd.read_csv(\"data/clean_rent_data_post_desc_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6c5cd",
   "metadata": {},
   "source": [
    "## Scaling The Data\n",
    "\n",
    "First we will scale the data so that it can be better trained against\n",
    "\n",
    "We left description in the cleaned data, but we should remove it before scaling because it is not a numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165ca7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f86375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=[\"description\"])\n",
    "test_df = test_df.drop(columns=[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748edc38",
   "metadata": {},
   "source": [
    "Let's also do some final data cleaning by dropping some outliers. Through inspection of the data, we see that some rentals are priced over 35000 per month and under 1000 per month. There are very few of these so they probably don't fit the standard pricing model, so we can drop them from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4a1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df[\"price\"] > 1000) & (train_df[\"price\"] < 35000)]\n",
    "test_df = test_df[(test_df[\"price\"] > 1000) & (test_df[\"price\"] < 35000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b09c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"price\"])\n",
    "Y_train = train_df[\"price\"]\n",
    "X_test = test_df.drop(columns=[\"price\"])\n",
    "Y_test = test_df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181257d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44319, 1228)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdbdc9",
   "metadata": {},
   "source": [
    "### Smaller Training Data\n",
    "Because we have so many columns, training models can take a lot of time.\n",
    "\n",
    "We'll further split the training set in order to speed that process up. In order to have fast training, we will split it up 50/50\n",
    "\n",
    "We will also be looking for the optimal hyper paramters which will further require many calculations which would be benefited by having a smaller training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d565726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, X_valid, Y_train_sm, Y_valid = train_test_split(X_train, Y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d058b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fitting the scaler to the training data and then also transforming the validation and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train_sm)\n",
    "\n",
    "# transform the test data without fitting (only fit on the train data)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077a1b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.56175846,  1.29704212, -0.66026   , ..., -0.41074614,\n",
       "       -0.11741095, -0.07127451])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that the numbers are now all around -2 to 2 as expected from scaling\n",
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bd11c",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "We will try a linear regression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe5f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7336617483233161\n",
      "Validation score: -3.39783241129853e+20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    " \n",
    "# Fit the model to the training data only\n",
    "lr_model.fit(X_train_scaled, Y_train_sm)\n",
    "\n",
    "lr_y_pred = lr_model.predict(X_valid_scaled)\n",
    " \n",
    "# scoring the train and test set\n",
    "print(f'Train score: {lr_model.score(X_train_scaled, Y_train_sm)}')\n",
    "print(f'Validation score: {lr_model.score(X_valid_scaled, Y_valid)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a228ee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4455052281119584e+27\n",
      "RMSE: 38019800474383.85\n",
      "MAE: 1368997117509.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "# calculating the MSE\n",
    "print(f'MSE: {mse(Y_valid, lr_y_pred)}')\n",
    " \n",
    "# calculating the RMSE\n",
    "print(f'RMSE: {np.sqrt(mse(Y_valid, lr_y_pred))}')\n",
    " \n",
    "# calculating the MAE\n",
    "print(f'MAE: {np.mean(np.abs(Y_valid - lr_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccfee0",
   "metadata": {},
   "source": [
    "The low test score indicates that the model is overfitted on the training data. Let's look at the coefficients to see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125ba646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coefficients_info(coefficients):\n",
    "    coeff_disp = [[round(coefficients[i]), X_train.columns[i]] for i in range(coefficients.shape[0])]\n",
    "    print(coefficients.shape)\n",
    "    print(sorted(coeff_disp, key=lambda x: abs(x[0]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c583699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228,)\n",
      "[[290597770110542, 'zipcode_10028'], [277220247137929, 'zipcode_10606'], [248345695923464, 'zipcode_10017'], [241375143810278, 'zipcode_10018'], [230659918237416, 'zipcode_10009'], [219190271775737, 'zipcode_10011'], [214051097963373, 'zipcode_10044'], [212180294997277, 'zipcode_10003'], [198780128823087, 'zipcode_10016'], [196027553904086, 'zipcode_11413'], [190898872997357, 'zipcode_10019'], [187612291889028, 'zipcode_10199'], [183279325969047, 'zipcode_08515'], [182035844951773, 'zipcode_10021'], [179326575620740, 'zipcode_10012'], [179174722103935, 'zipcode_10023'], [176416497480598, 'zipcode_10162'], [169787268455130, 'zipcode_10002'], [169140953740357, 'zipcode_10025'], [168003326439953, 'zipcode_10271'], [167185531201793, 'zipcode_10001'], [160478693264923, 'zipcode_10065'], [-157291936148962, 'zipcode_11412'], [155257929422137, 'zipcode_08088'], [147193780873749, 'zipcode_10022'], [146570289078940, 'desc_word_ellimancoma'], [143568668418574, 'zipcode_10005'], [143506450083787, 'zipcode_11364'], [140430961720787, 'zipcode_11694'], [-139145228173449, 'desc_word_width1'], [135938936364848, 'zipcode_06901'], [126654884143200, 'zipcode_10029'], [126433803919060, 'zipcode_11201'], [125990417964502, 'zipcode_10006'], [123067426005009, 'zipcode_10032'], [122153251980864, 'zipcode_10026'], [120303031852160, 'zipcode_10069'], [115784589507863, 'zipcode_10014'], [115298191853422, 'zipcode_11211'], [112090205848024, 'desc_word_coopercoopercomsearchrent'], [-109847616994481, 'zipcode_10706'], [107727497489388, 'zipcode_10280'], [106359079748719, 'zipcode_10305'], [105613304985972, 'zipcode_10038'], [103998412925441, 'zipcode_10034'], [103181150317932, 'zipcode_10030'], [102632566937761, 'zipcode_10103'], [101829779232392, 'zipcode_11229'], [101526201739404, 'zipcode_10031'], [100688180083112, 'zipcode_10154'], [91874610615174, 'zipcode_11217'], [90944878912185, 'zipcode_11238'], [90272105704908, 'zipcode_07111'], [88416522474546, 'zipcode_11109'], [86470495696584, 'zipcode_10013'], [86145310287691, 'zipcode_10301'], [86141778586235, 'zipcode_10027'], [85480461248234, 'zipcode_10007'], [84813865395726, 'zipcode_11237'], [83464331258792, 'zipcode_11215'], [82058452668195, 'zipcode_11780'], [81564397025797, 'zipcode_10455'], [80696043905785, 'zipcode_10039'], [80343156494921, 'zipcode_11102'], [78915500042564, 'zipcode_11233'], [78679771475661, 'created_year'], [-77977298579930, 'zipcode_02494'], [77093003802334, 'zipcode_10035'], [76723208393144, 'zipcode_10278'], [75225506093231, 'zipcode_11216'], [71341286507902, 'zipcode_11106'], [71341286507861, 'zipcode_10020'], [70940967695054, 'zipcode_10282'], [70538340299191, 'zipcode_10171'], [67651816171464, 'zipcode_11221'], [67229185089870, 'zipcode_11375'], [66991126931995, 'desc_word_informationa'], [65944806648053, 'zipcode_11205'], [64952151655284, 'zipcode_19355'], [64191774396573, 'zipcode_10167'], [63745882522770, 'zipcode_11101'], [62388840030025, 'zipcode_11222'], [61929801143393, 'zipcode_11226'], [59099821474440, 'zipcode_11220'], [-58673219267798, 'desc_word_lilia'], [58614721118950, 'zipcode_11374'], [58614721118867, 'zipcode_10110'], [58614721118856, 'zipcode_11213'], [56632325073972, 'zipcode_11103'], [55614355209942, 'zipcode_10153'], [-55368547054744, 'zipcode_11356'], [55098247368538, 'zipcode_10119'], [54577211714156, 'zipcode_10037'], [53519779918507, 'zipcode_11104'], [53519779918448, 'zipcode_11231'], [52983077214677, 'zipcode_11218'], [-52007206115451, 'desc_word_coopercoopercomassoci'], [51339013073886, 'zipcode_10468'], [50779062249752, 'zipcode_11225'], [48474085226726, 'zipcode_11206'], [-46093865606643, 'desc_word_coopercoopercombuyingseminar'], [45427415259326, 'zipcode_11415'], [45427415259138, 'zipcode_10463'], [45348632472443, 'zipcode_07643'], [44149507683672, 'zipcode_11105'], [42833249599312, 'zipcode_11372'], [41474989869809, 'zipcode_11235'], [40778802925544, 'zipcode_11373'], [40778802925497, 'zipcode_11210'], [37865589639427, 'zipcode_11209'], [36321038538626, 'zipcode_11354'], [32135098495751, 'zipcode_11351'], [32135098495658, 'zipcode_10458'], [31443948520021, 'desc_word_ullia'], [-31443948519923, 'desc_word_height1'], [-31218627355161, 'zipcode_10475'], [27312665807958, 'zipcode_11377'], [27312665807912, 'zipcode_11204'], [25125132854872, 'zipcode_11421'], [25125132854822, 'zipcode_11230'], [25125132854821, 'zipcode_11223'], [25125132854798, 'zipcode_11219'], [23956415034312, 'zipcode_11385'], [22727563867608, 'zipcode_11435'], [22727563867591, 'zipcode_11368'], [22727563867522, 'zipcode_10452'], [22727563867509, 'zipcode_11228'], [22727563867496, 'zipcode_07310'], [-21701987039399, 'desc_word_seminar'], [21428236398505, 'zipcode_11367'], [21428236398460, 'zipcode_11203'], [21428236398434, 'zipcode_10467'], [21428236398423, 'zipcode_11212'], [20044732192772, 'zipcode_11355'], [20044732192724, 'zipcode_11379'], [18558234828369, 'zipcode_11207'], [18558234828364, 'zipcode_10469'], [18558234828351, 'zipcode_10152'], [18558234828348, 'zipcode_10454'], [16941655437127, 'zipcode_11581'], [16941655437039, 'zipcode_10472'], [16941655437018, 'zipcode_10471'], [-15615083113195, 'desc_word_target_blank'], [15153419274592, 'zipcode_02199'], [15153419273771, 'zipcode_11432'], [15153419273755, 'zipcode_11416'], [15153419273744, 'zipcode_11208'], [15153419273728, 'zipcode_10470'], [15153419273726, 'zipcode_10460'], [15153419273709, 'zipcode_07093'], [15153419273705, 'zipcode_11214'], [15153419273689, 'zipcode_07030'], [13123542210893, 'zipcode_11361'], [13123542210891, 'zipcode_11358'], [13123542210877, 'zipcode_11236'], [13123542210856, 'zipcode_11378'], [13123542210840, 'zipcode_10456'], [13123542210838, 'zipcode_10457'], [13123542210822, 'zipcode_07311'], [10715569157619, 'zipcode_11004'], [10715569157614, 'zipcode_11691'], [10715569157589, 'zipcode_11360'], [10715569157576, 'zipcode_10461'], [10715569157563, 'zipcode_10024'], [10715569157563, 'zipcode_10111'], [10715569157561, 'zipcode_10004'], [10715569157551, 'zipcode_10453'], [10715569157547, 'zipcode_07024'], [9725995921053, 'zipcode_11428'], [7712852913201, 'desc_word_coopercoopercomtestimoni'], [7577222599611, 'zipcode_02169'], [7577222599543, 'zipcode_11937'], [7577222599196, 'zipcode_11427'], [7577222599190, 'zipcode_11433'], [7577222599189, 'zipcode_11419'], [7577222599186, 'zipcode_11418'], [7577222599186, 'zipcode_11423'], [7577222599184, 'zipcode_10801'], [7577222599180, 'zipcode_11692'], [7577222599178, 'zipcode_11357'], [7577222599177, 'zipcode_10465'], [7577222599176, 'zipcode_11417'], [7577222599175, 'zipcode_10553'], [7577222599174, 'zipcode_11366'], [7577222599166, 'zipcode_10462'], [7577222599165, 'zipcode_10459'], [7577222599163, 'zipcode_10112'], [7577222599163, 'zipcode_10474'], [7577222599163, 'zipcode_11369'], [7577222599162, 'zipcode_11370'], [7577222599159, 'zipcode_10705'], [7577222599158, 'zipcode_07086'], [7577222599154, 'zipcode_11224'], [7577222599151, 'zipcode_10451'], [7577222599151, 'zipcode_10466'], [7577222599147, 'zipcode_10115'], [7577222599147, 'zipcode_10591'], [7577222599136, 'zipcode_10304'], [7577222599136, 'zipcode_10522'], [7577222599132, 'zipcode_07102'], [7577222599131, 'zipcode_07031'], [7577222599127, 'zipcode_10314'], [7577222599116, 'zipcode_12094'], [7577222599115, 'zipcode_10307'], [7577222599103, 'zipcode_07028'], [7577222599095, 'zipcode_07042'], [7577222599081, 'zipcode_08805'], [7577222599077, 'zipcode_08904'], [7577222599025, 'zipcode_07921'], [7577222598529, 'zipcode_13166'], [6141, 'created_day'], [-6117, 'created_epoch_secs'], [-1575, 'longitude'], [-1164, 'desc_word_226-317-8312'], [903, 'bathrooms'], [676, 'desc_word_wwwhgrnycomva'], [667, 'bedrooms'], [548, 'desc_word_listings-------'], [484, 'latitude'], [-418, 'desc_word_href'], [314, 'desc_word_error'], [-277, 'desc_word_omiss'], [240, 'desc_word_coopercoopercom'], [217, 'doorman'], [-216, 'desc_word_000-420-2751'], [179, 'desc_word_campc'], [-175, 'desc_word_withdraw'], [169, 'desc_word_src'], [137, 'desc_word_-disclosur'], [-110, 'desc_word_flex'], [106, 'desc_word_master'], [95, 'desc_word_deem'], [93, 'desc_word_chef'], [-90, 'desc_word_1000'], [87, 'desc_word_separ'], [-85, 'desc_word_correct'], [80, 'desc_word_suit'], [78, 'desc_word_purpos'], [78, 'desc_word_wwwmironpropertiescompa'], [77, 'laundry_in_unit'], [-76, 'desc_word_convert'], [74, 'desc_word_overlook'], [73, 'desc_word_areaneighborhood'], [72, 'desc_word_penthous'], [71, 'desc_word_ultim'], [70, 'elevator'], [67, 'desc_word_reliabl'], [66, 'desc_word_central'], [66, 'desc_word_maid'], [-63, 'hardwood_floors'], [63, 'desc_word_fireplac'], [63, 'desc_word_soho'], [62, 'desc_word_gourmet'], [-61, 'desc_word_believ'], [61, 'desc_word_tal'], [60, 'desc_word_24'], [-58, 'desc_word_miron'], [-56, 'desc_word_databas'], [-56, 'desc_word_hour'], [-56, 'desc_word_opportunitypa'], [56, 'desc_word_room'], [56, 'desc_word_servic'], [55, 'dogs_allowed'], [-55, 'desc_word_brick'], [54, 'desc_word_pre-war'], [53, 'fitness_center'], [53, 'desc_word_dine'], [53, 'desc_word_loft'], [-53, 'desc_word_noticebr'], [52, 'desc_word_equal'], [52, 'desc_word_terrac'], [52, 'desc_word_washer'], [51, 'desc_word_david'], [51, 'desc_word_entri'], [-50, 'outdoor_space'], [-50, 'desc_word_support'], [49, 'desc_word_present'], [-49, 'desc_word_valet'], [48, 'desc_word_condo'], [-48, 'desc_word_contact'], [47, 'desc_word_exclus'], [-46, 'desc_word_columbu'], [46, 'desc_word_estat'], [46, 'desc_word_york'], [-45, 'desc_word_bath'], [45, 'desc_word_expos'], [-44, 'desc_word_design'], [44, 'desc_word_sprawl'], [43, 'desc_word_deck'], [-43, 'desc_word_everi'], [-43, 'desc_word_select'], [43, 'desc_word_sourc'], [42, 'desc_word_buy'], [-42, 'desc_word_fax'], [-42, 'desc_word_friendli'], [-42, 'desc_word_wall'], [-41, 'subway_distance_max_4000'], [41, 'desc_word_applianc'], [40, 'desc_word_boutiqu'], [-40, 'desc_word_chang'], [-40, 'desc_word_kagglemanagerrenthopcom'], [40, 'desc_word_phone'], [-40, 'desc_word_real'], [-39, 'desc_word_bedroom'], [38, 'dining_room'], [-38, 'new_construction'], [38, 'desc_word_feet'], [-38, 'desc_word_text'], [37, 'desc_word_architectur'], [-37, 'desc_word_closet'], [-37, 'desc_word_fine'], [37, 'desc_word_qualiti'], [36, 'desc_word_directli'], [36, 'desc_word_elev'], [-36, 'desc_word_hous'], [36, 'desc_word_post-war'], [-36, 'desc_word_price'], [-35, 'desc_word_featur'], [35, 'desc_word_finish'], [35, 'desc_word_thought'], [-34, 'desc_word_deal'], [34, 'desc_word_home'], [34, 'desc_word_metropolitan'], [-34, 'desc_word_properti'], [34, 'desc_word_sf'], [34, 'desc_word_subject'], [34, 'desc_word_washerdry'], [-33, 'high_speed_internet'], [33, 'garden_patio'], [33, 'desc_word_13'], [-33, 'desc_word_duplex'], [-33, 'desc_word_emporium'], [33, 'desc_word_lap'], [33, 'desc_word_open'], [-33, 'desc_word_renov'], [-33, 'desc_word_roof'], [33, 'desc_word_spectacular'], [32, 'desc_word_air'], [32, 'desc_word_compil'], [32, 'desc_word_immacul'], [32, 'desc_word_inform'], [-32, 'desc_word_surround'], [-31, 'no_fee'], [31, 'desc_word_amp'], [31, 'desc_word_attend'], [-31, 'desc_word_bathroom'], [-31, 'desc_word_bond'], [-31, 'desc_word_conv'], [31, 'desc_word_cool'], [31, 'desc_word_dryer'], [31, 'desc_word_landlord'], [-31, 'desc_word_laundri'], [-31, 'desc_word_love'], [31, 'desc_word_madison'], [31, 'desc_word_parti'], [31, 'desc_word_spa'], [30, 'terrace'], [-30, 'desc_word_247'], [30, 'desc_word_40x'], [30, 'desc_word_5th'], [-30, 'desc_word_cherri'], [30, 'desc_word_citi'], [-30, 'desc_word_notic'], [30, 'desc_word_restaur'], [30, 'desc_word_wide'], [-29, 'pre-war'], [29, 'desc_word_abov'], [29, 'desc_word_apart'], [-29, 'desc_word_associ'], [29, 'desc_word_children'], [-29, 'desc_word_club'], [-29, 'desc_word_courtesi'], [-29, 'desc_word_cover'], [-29, 'desc_word_direct'], [29, 'desc_word_exposur'], [-29, 'desc_word_locat'], [29, 'desc_word_month'], [-29, 'desc_word_sauna'], [-29, 'desc_word_small'], [-29, 'desc_word_subway'], [29, 'desc_word_trader'], [29, 'desc_word_view'], [-29, 'desc_word_waterfront'], [29, 'desc_word_wine'], [-28, 'cats_allowed'], [28, 'desc_word_crown'], [28, 'desc_word_eat'], [-28, 'desc_word_link'], [-28, 'desc_word_microwav'], [28, 'desc_word_opportun'], [27, 'desc_word_broker'], [-27, 'desc_word_empir'], [27, 'desc_word_fresh'], [27, 'desc_word_icon'], [27, 'desc_word_interior'], [27, 'desc_word_lot'], [-27, 'desc_word_mid'], [27, 'desc_word_onlin'], [27, 'desc_word_park'], [-27, 'desc_word_residenti'], [-27, 'desc_word_seaport'], [-27, 'desc_word_sunni'], [26, 'wheelchair_access'], [-26, 'desc_word_2nd'], [26, 'desc_word_86th'], [26, 'desc_word_anyth'], [26, 'desc_word_appoint'], [-26, 'desc_word_basketbal'], [-26, 'desc_word_brooklyn'], [-26, 'desc_word_center'], [-26, 'desc_word_clean'], [26, 'desc_word_condominium'], [-26, 'desc_word_countertop'], [-26, 'desc_word_courtyard'], [26, 'desc_word_differ'], [26, 'desc_word_doe'], [26, 'desc_word_fulli'], [-26, 'desc_word_hudson'], [26, 'desc_word_incred'], [-26, 'desc_word_low'], [26, 'desc_word_mosaic'], [26, 'desc_word_wrap'], [25, 'desc_word_747-575-4675'], [25, 'desc_word_avenu'], [-25, 'desc_word_kitchen'], [-25, 'desc_word_movi'], [-25, 'desc_word_new'], [-25, 'desc_word_perfect'], [-25, 'desc_word_porcelain'], [25, 'desc_word_prewar'], [-25, 'desc_word_read'], [-25, 'desc_word_size'], [-25, 'desc_word_stainless'], [-24, 'desc_word_addit'], [24, 'desc_word_brand'], [-24, 'desc_word_event'], [-24, 'desc_word_gut'], [-24, 'desc_word_life'], [-24, 'desc_word_rain'], [24, 'desc_word_sophist'], [-23, 'desc_word_-------------list'], [23, 'desc_word_class'], [-23, 'desc_word_drop'], [-23, 'desc_word_field'], [23, 'desc_word_furnish'], [23, 'desc_word_height'], [-23, 'desc_word_joe'], [-23, 'desc_word_make'], [-23, 'desc_word_mani'], [-23, 'desc_word_mid-ris'], [-23, 'desc_word_transport'], [-23, 'desc_word_util'], [-22, 'desc_word_3br'], [-22, 'desc_word_add'], [-22, 'desc_word_block'], [22, 'desc_word_habitat'], [22, 'desc_word_health'], [-22, 'desc_word_includ'], [22, 'desc_word_origin'], [22, 'desc_word_privat'], [22, 'desc_word_shaker'], [-22, 'desc_word_shuttl'], [-22, 'desc_word_steam'], [-22, 'desc_word_style'], [22, 'desc_word_thi'], [22, 'desc_word_wd'], [21, 'desc_word_built-in'], [21, 'desc_word_classic'], [21, 'desc_word_custom'], [-21, 'desc_word_easi'], [21, 'desc_word_eat-in'], [21, 'desc_word_eleg'], [21, 'desc_word_end'], [-21, 'desc_word_enjoy'], [-21, 'desc_word_gem'], [21, 'desc_word_heat'], [-21, 'desc_word_high-ris'], [21, 'desc_word_hub'], [21, 'desc_word_lincoln'], [21, 'desc_word_process'], [-21, 'desc_word_regard'], [-21, 'desc_word_rise'], [-21, 'desc_word_rooftop'], [-21, 'desc_word_tile'], [-21, 'desc_word_trainbr'], [21, 'desc_word_upscal'], [-20, 'exclusive'], [20, 'desc_word_10'], [-20, 'desc_word_assist'], [-20, 'desc_word_bright'], [-20, 'desc_word_choic'], [20, 'desc_word_condit'], [20, 'desc_word_easili'], [-20, 'desc_word_fun'], [-20, 'desc_word_guarantor'], [-20, 'desc_word_hesit'], [-20, 'desc_word_live'], [-20, 'desc_word_need'], [20, 'desc_word_newli'], [20, 'desc_word_oak'], [20, 'desc_word_refriger'], [-20, 'desc_word_studio'], [-20, 'desc_word_ultra'], [20, 'desc_word_wa'], [20, 'desc_word_williamsburg'], [-19, 'balcony'], [19, 'desc_word_accept'], [-19, 'desc_word_befor'], [-19, 'desc_word_bicycl'], [-19, 'desc_word_concierg'], [-19, 'desc_word_counter'], [-19, 'desc_word_drive'], [-19, 'desc_word_friendlybr'], [-19, 'desc_word_ge'], [-19, 'desc_word_group'], [-19, 'desc_word_hr'], [19, 'desc_word_ill'], [19, 'desc_word_island'], [-19, 'desc_word_june'], [19, 'desc_word_licens'], [-19, 'desc_word_multipl'], [-19, 'desc_word_note'], [-19, 'desc_word_queen'], [-19, 'desc_word_quiet'], [19, 'desc_word_rang'], [-19, 'desc_word_sleek'], [-19, 'desc_word_storag'], [-19, 'desc_word_true'], [19, 'desc_word_veri'], [-19, 'desc_word_whi'], [-18, 'desc_word_allow'], [-18, 'desc_word_ani'], [18, 'desc_word_bay'], [-18, 'desc_word_bed'], [-18, 'desc_word_cell'], [-18, 'desc_word_commun'], [18, 'desc_word_dagostino'], [-18, 'desc_word_decor'], [18, 'desc_word_doesnt'], [18, 'desc_word_famili'], [18, 'desc_word_fixtur'], [18, 'desc_word_full-servic'], [-18, 'desc_word_indoor'], [-18, 'desc_word_insid'], [-18, 'desc_word_monthli'], [-18, 'desc_word_natur'], [-18, 'desc_word_neighborhood'], [-18, 'desc_word_occup'], [18, 'desc_word_outsid'], [-18, 'desc_word_profession'], [-18, 'desc_word_second'], [-18, 'desc_word_sleep'], [-18, 'desc_word_sundeck'], [-18, 'desc_word_sunlight'], [18, 'desc_word_town'], [18, 'desc_word_tub'], [18, 'desc_word_uw'], [18, 'desc_word_walk-in'], [-18, 'desc_word_water'], [18, 'desc_word_websit'], [17, 'loft'], [-17, 'very_far_from_subway'], [-17, 'desc_word_15'], [-17, 'desc_word_brownston'], [17, 'desc_word_comfort'], [-17, 'desc_word_dish'], [-17, 'desc_word_excit'], [-17, 'desc_word_floors-'], [17, 'desc_word_ga'], [17, 'desc_word_granit'], [-17, 'desc_word_hardwood'], [-17, 'desc_word_live-in'], [-17, 'desc_word_lux'], [17, 'desc_word_middl'], [-17, 'desc_word_miss'], [17, 'desc_word_offer'], [17, 'desc_word_oven'], [-17, 'desc_word_overs'], [-17, 'desc_word_proxim'], [17, 'desc_word_retail'], [17, 'desc_word_ride'], [-17, 'desc_word_sink'], [17, 'desc_word_space'], [-17, 'desc_word_station'], [17, 'desc_word_townhous'], [17, 'desc_word_white'], [17, 'desc_word_window'], [17, 'desc_word_wonder'], [-17, 'desc_word_wood'], [16, 'common_outdoor_space'], [-16, 'desc_word_2br'], [-16, 'desc_word_501-606-3449br'], [16, 'desc_word_best'], [-16, 'desc_word_big'], [-16, 'desc_word_calltext'], [16, 'desc_word_control'], [-16, 'desc_word_european'], [16, 'desc_word_foot'], [-16, 'desc_word_free'], [-16, 'desc_word_greenwich'], [-16, 'desc_word_ha'], [-16, 'desc_word_in-unit'], [-16, 'desc_word_lexington'], [-16, 'desc_word_locationbr'], [-16, 'desc_word_low-ris'], [-16, 'desc_word_midtown'], [16, 'desc_word_option'], [-16, 'desc_word_pa'], [16, 'desc_word_playroom'], [16, 'desc_word_proof'], [-16, 'desc_word_relax'], [16, 'desc_word_shower'], [16, 'desc_word_social'], [16, 'desc_word_south'], [16, 'desc_word_sqft'], [16, 'desc_word_summer'], [16, 'desc_word_term'], [16, 'desc_word_tv'], [-16, 'desc_word_valu'], [16, 'desc_word_wait'], [-16, 'desc_word_walk'], [16, 'desc_word_youll'], [15, 'desc_word_40'], [-15, 'desc_word_better'], [-15, 'desc_word_cardio'], [-15, 'desc_word_chri'], [-15, 'desc_word_extra'], [-15, 'desc_word_facil'], [15, 'desc_word_level'], [15, 'desc_word_like'], [-15, 'desc_word_liulp'], [-15, 'desc_word_mile'], [15, 'desc_word_path'], [15, 'desc_word_pet-friendli'], [-15, 'desc_word_playground'], [15, 'desc_word_pleasur'], [-15, 'desc_word_reflect'], [-15, 'desc_word_share'], [-15, 'desc_word_shop'], [15, 'desc_word_sit'], [-15, 'desc_word_thing'], [-15, 'desc_word_unit'], [-14, 'desc_word_actual'], [14, 'desc_word_ampl'], [-14, 'desc_word_applic'], [-14, 'desc_word_approv'], [-14, 'desc_word_batteri'], [14, 'desc_word_construct'], [14, 'desc_word_cooper'], [-14, 'desc_word_doorman'], [14, 'desc_word_e-mail'], [14, 'desc_word_endless'], [14, 'desc_word_entranc'], [-14, 'desc_word_fabul'], [14, 'desc_word_features-'], [14, 'desc_word_hard'], [-14, 'desc_word_harlem'], [-14, 'desc_word_hi'], [-14, 'desc_word_individu'], [-14, 'desc_word_kagglemanagerrenthopcombr'], [-14, 'desc_word_loung'], [14, 'desc_word_manag'], [-14, 'desc_word_murray'], [-14, 'desc_word_packag'], [-14, 'desc_word_provid'], [14, 'desc_word_public'], [14, 'desc_word_requir'], [-14, 'desc_word_search'], [-14, 'desc_word_secur'], [-14, 'desc_word_shown'], [14, 'desc_word_similar'], [-14, 'desc_word_store'], [-14, 'desc_word_vaniti'], [14, 'desc_word_virtual'], [13, 'desc_word_80'], [-13, 'desc_word_activ'], [-13, 'desc_word_afford'], [-13, 'desc_word_asap'], [-13, 'desc_word_cabinetri'], [-13, 'desc_word_close'], [-13, 'desc_word_contemporari'], [-13, 'desc_word_court'], [13, 'desc_word_descript'], [13, 'desc_word_drench'], [13, 'desc_word_enorm'], [-13, 'desc_word_enter'], [-13, 'desc_word_famou'], [13, 'desc_word_glove'], [13, 'desc_word_incompar'], [13, 'desc_word_info'], [-13, 'desc_word_market'], [13, 'desc_word_modern'], [-13, 'desc_word_nyu'], [-13, 'desc_word_ok'], [-13, 'desc_word_over-s'], [-13, 'desc_word_popular'], [13, 'desc_word_question'], [-13, 'desc_word_recess'], [-13, 'desc_word_rich'], [-13, 'desc_word_soar'], [-13, 'desc_word_spacebr'], [-13, 'desc_word_star'], [13, 'desc_word_start'], [-13, 'desc_word_tenant'], [13, 'desc_word_total'], [-13, 'desc_word_transit'], [13, 'desc_word_va'], [-13, 'desc_word_varieti'], [-13, 'desc_word_washington'], [-12, 'desc_word_123'], [-12, 'desc_word_24hr'], [12, 'desc_word_8th'], [12, 'desc_word_anytim'], [-12, 'desc_word_anytimebr'], [-12, 'desc_word_attract'], [-12, 'desc_word_beat'], [-12, 'desc_word_cafe'], [12, 'desc_word_chic'], [-12, 'desc_word_colleg'], [12, 'desc_word_concess'], [-12, 'desc_word_cook'], [12, 'desc_word_cooler'], [12, 'desc_word_deckbr'], [-12, 'desc_word_floor-to-ceil'], [12, 'desc_word_floorsbr'], [12, 'desc_word_glass'], [12, 'desc_word_hell'], [-12, 'desc_word_high'], [-12, 'desc_word_inquiri'], [-12, 'desc_word_larg'], [-12, 'desc_word_layout'], [-12, 'desc_word_long'], [-12, 'desc_word_major'], [12, 'desc_word_music'], [-12, 'desc_word_net'], [-12, 'desc_word_pass'], [12, 'desc_word_pet'], [12, 'desc_word_plan'], [12, 'desc_word_play'], [12, 'desc_word_quit'], [12, 'desc_word_rental'], [-12, 'desc_word_request'], [-12, 'desc_word_seat'], [12, 'desc_word_sq'], [12, 'desc_word_state'], [-12, 'desc_word_trendi'], [12, 'desc_word_tribeca'], [12, 'desc_word_web'], [11, 'dishwasher'], [-11, 'desc_word_1st'], [-11, 'desc_word_ac'], [-11, 'desc_word_advertis'], [11, 'desc_word_balconi'], [-11, 'desc_word_bathbr'], [11, 'desc_word_black'], [11, 'desc_word_bridg'], [11, 'desc_word_din'], [-11, 'desc_word_dishwash'], [11, 'desc_word_dri'], [-11, 'desc_word_effici'], [-11, 'desc_word_els'], [-11, 'desc_word_email'], [11, 'desc_word_energi'], [11, 'desc_word_favorit'], [11, 'desc_word_feel'], [11, 'desc_word_floor'], [11, 'desc_word_fulton'], [11, 'desc_word_garag'], [11, 'desc_word_gener'], [-11, 'desc_word_hallway'], [11, 'desc_word_impress'], [-11, 'desc_word_junior'], [11, 'desc_word_kind'], [11, 'desc_word_leas'], [11, 'desc_word_local'], [11, 'desc_word_nearbi'], [11, 'desc_word_onli'], [11, 'desc_word_pay'], [11, 'desc_word_pleas'], [-11, 'desc_word_prime'], [-11, 'desc_word_right'], [-11, 'desc_word_screen'], [-11, 'desc_word_spot'], [11, 'desc_word_transportationbr'], [-11, 'desc_word_unbeat'], [-10, 'desc_word_30'], [-10, 'desc_word_3rd'], [10, 'desc_word_50'], [-10, 'desc_word_7th'], [10, 'desc_word_aaron'], [10, 'desc_word_ask'], [10, 'desc_word_availablebr'], [-10, 'desc_word_awaybr'], [-10, 'desc_word_bldg'], [-10, 'desc_word_build'], [10, 'desc_word_cat'], [-10, 'desc_word_clinton'], [-10, 'desc_word_enhanc'], [10, 'desc_word_fee'], [-10, 'desc_word_golf'], [10, 'desc_word_grand'], [-10, 'desc_word_guest'], [10, 'desc_word_hall'], [-10, 'desc_word_huge'], [-10, 'desc_word_mapl'], [-10, 'desc_word_mirror'], [-10, 'desc_word_nestl'], [10, 'desc_word_pool'], [-10, 'desc_word_seebr'], [-10, 'desc_word_set'], [10, 'desc_word_thousand'], [-10, 'desc_word_today'], [-10, 'desc_word_walk-up'], [-9, 'desc_word_alcov'], [-9, 'desc_word_bathtub'], [-9, 'desc_word_boast'], [-9, 'desc_word_bosch'], [-9, 'desc_word_built'], [-9, 'desc_word_cleaner'], [-9, 'desc_word_columbia'], [-9, 'desc_word_downtown'], [-9, 'desc_word_eastern'], [-9, 'desc_word_electr'], [-9, 'desc_word_face'], [9, 'desc_word_foyer'], [-9, 'desc_word_good'], [-9, 'desc_word_great'], [9, 'desc_word_instal'], [-9, 'desc_word_king-siz'], [-9, 'desc_word_leav'], [-9, 'desc_word_librari'], [-9, 'desc_word_light'], [-9, 'desc_word_look'], [9, 'desc_word_lower'], [9, 'desc_word_museum'], [9, 'desc_word_pic'], [9, 'desc_word_recreat'], [9, 'desc_word_site'], [9, 'desc_word_skylight'], [9, 'desc_word_todaybr'], [-9, 'desc_word_uniqu'], [-9, 'desc_word_welcom'], [8, 'desc_word_11'], [-8, 'desc_word_501-606-3449'], [-8, 'desc_word_appliancesbr'], [-8, 'desc_word_bar'], [8, 'desc_word_beauti'], [-8, 'desc_word_br'], [8, 'desc_word_building-'], [-8, 'desc_word_cultur'], [8, 'desc_word_deli'], [-8, 'desc_word_distanc'], [-8, 'desc_word_experi'], [8, 'desc_word_gorgeou'], [8, 'desc_word_gramerci'], [8, 'desc_word_head'], [8, 'desc_word_hi-ris'], [8, 'desc_word_hill'], [-8, 'desc_word_hundr'], [8, 'desc_word_ideal'], [-8, 'desc_word_landscap'], [8, 'desc_word_maintain'], [8, 'desc_word_meet'], [-8, 'desc_word_minut'], [8, 'desc_word_north'], [-8, 'desc_word_number'], [-8, 'desc_word_nyc'], [-8, 'desc_word_place'], [8, 'desc_word_plenti'], [-8, 'desc_word_queen-siz'], [-8, 'desc_word_reach'], [-8, 'desc_word_sound'], [-8, 'desc_word_ss'], [-8, 'desc_word_steal'], [8, 'desc_word_stone'], [-8, 'desc_word_sure'], [8, 'desc_word_tenni'], [-8, 'desc_word_train'], [8, 'desc_word_trainsbr'], [8, 'desc_word_viewsbr'], [8, 'desc_word_want'], [-8, 'desc_word_year'], [7, 'roof_deck'], [-7, 'desc_word_20'], [7, 'desc_word_areabr'], [7, 'desc_word_ave'], [-7, 'desc_word_backyard'], [7, 'desc_word_bu'], [-7, 'desc_word_common'], [7, 'desc_word_doorstep'], [7, 'desc_word_flat'], [7, 'desc_word_full-tim'], [7, 'desc_word_happi'], [7, 'desc_word_hot'], [7, 'desc_word_key'], [-7, 'desc_word_king'], [-7, 'desc_word_list'], [7, 'desc_word_magnific'], [-7, 'desc_word_mass'], [-7, 'desc_word_massiv'], [-7, 'desc_word_match'], [-7, 'desc_word_offerbr'], [7, 'desc_word_outdoor'], [-7, 'desc_word_panoram'], [7, 'desc_word_recent'], [7, 'desc_word_rentbr'], [-7, 'desc_word_riversid'], [7, 'desc_word_showingbr'], [-7, 'desc_word_sorri'], [7, 'desc_word_speed'], [-7, 'desc_word_stand'], [-7, 'desc_word_starbuck'], [7, 'desc_word_steel'], [-7, 'desc_word_step'], [7, 'desc_word_union'], [7, 'desc_word_updat'], [-7, 'desc_word_world'], [-6, 'desc_word_accent'], [6, 'desc_word_airi'], [-6, 'desc_word_alway'], [-6, 'desc_word_array'], [-6, 'desc_word_bold'], [-6, 'desc_word_busi'], [6, 'desc_word_choos'], [6, 'desc_word_combin'], [-6, 'desc_word_come'], [-6, 'desc_word_crosstown'], [-6, 'desc_word_deep'], [6, 'desc_word_district'], [-6, 'desc_word_door'], [6, 'desc_word_entertain'], [6, 'desc_word_entir'], [6, 'desc_word_everyth'], [6, 'desc_word_expans'], [-6, 'desc_word_extrem'], [-6, 'desc_word_financi'], [-6, 'desc_word_flight'], [-6, 'desc_word_french'], [6, 'desc_word_furnitur'], [-6, 'desc_word_im'], [-6, 'desc_word_immedi'], [6, 'desc_word_inquir'], [-6, 'desc_word_intercom'], [-6, 'desc_word_kept'], [-6, 'desc_word_lead'], [-6, 'desc_word_let'], [-6, 'desc_word_lobbi'], [-6, 'desc_word_materi'], [6, 'desc_word_mold'], [6, 'desc_word_numer'], [-6, 'desc_word_plaza'], [6, 'desc_word_pre'], [-6, 'desc_word_send'], [-6, 'desc_word_sought'], [-6, 'desc_word_southern'], [-6, 'desc_word_stori'], [6, 'desc_word_street'], [-6, 'desc_word_stylish'], [-6, 'desc_word_sun'], [-6, 'desc_word_super'], [-6, 'desc_word_ton'], [6, 'desc_word_tree'], [-6, 'desc_word_upgrad'], [-6, 'desc_word_week'], [-6, 'desc_word_weight'], [6, 'desc_word_xl'], [-5, 'desc_word_100'], [5, 'desc_word_12'], [5, 'desc_word_23'], [5, 'desc_word_agent'], [-5, 'desc_word_alreadi'], [-5, 'desc_word_anywher'], [5, 'desc_word_area'], [5, 'desc_word_avail'], [-5, 'desc_word_away'], [5, 'desc_word_bohemia'], [5, 'desc_word_breathtak'], [-5, 'desc_word_cabinet'], [-5, 'desc_word_calltextemail'], [5, 'desc_word_case'], [5, 'desc_word_charm'], [5, 'desc_word_closetsbr'], [5, 'desc_word_coffe'], [-5, 'desc_word_complet'], [-5, 'desc_word_date'], [-5, 'desc_word_deco'], [5, 'desc_word_dm'], [5, 'desc_word_doubl'], [-5, 'desc_word_effect'], [-5, 'desc_word_express'], [-5, 'desc_word_fast'], [-5, 'desc_word_groceri'], [-5, 'desc_word_gym'], [-5, 'desc_word_hotel'], [-5, 'desc_word_incom'], [-5, 'desc_word_internet'], [-5, 'desc_word_littl'], [5, 'desc_word_machin'], [-5, 'desc_word_min'], [-5, 'desc_word_on-sit'], [5, 'desc_word_parkbr'], [5, 'desc_word_parquet'], [5, 'desc_word_person'], [5, 'desc_word_pristin'], [5, 'desc_word_realti'], [5, 'desc_word_respons'], [5, 'desc_word_review'], [-5, 'desc_word_short'], [-5, 'desc_word_simpli'], [-5, 'desc_word_soak'], [-5, 'desc_word_space-'], [5, 'desc_word_tower'], [-5, 'desc_word_tree-lin'], [-5, 'desc_word_unitbr'], [-5, 'desc_word_visit'], [-5, 'desc_word_voic'], [-5, 'desc_word_warm'], [-5, 'desc_word_west'], [-5, 'desc_word_wont'], [-5, 'desc_word_work'], [4, 'swimming_pool'], [-4, 'desc_word_1br'], [4, 'desc_word_25'], [-4, 'desc_word_advantag'], [-4, 'desc_word_awesom'], [-4, 'desc_word_bbq'], [-4, 'desc_word_billiard'], [-4, 'desc_word_buse'], [4, 'desc_word_ceil'], [4, 'desc_word_complimentari'], [-4, 'desc_word_conveni'], [4, 'desc_word_credit'], [-4, 'desc_word_dark'], [-4, 'desc_word_excel'], [4, 'desc_word_fairway'], [4, 'desc_word_fantast'], [4, 'desc_word_feebr'], [4, 'desc_word_finest'], [-4, 'desc_word_fit'], [-4, 'desc_word_fridg'], [-4, 'desc_word_galleri'], [-4, 'desc_word_housekeep'], [4, 'desc_word_kohler'], [4, 'desc_word_landmark'], [4, 'desc_word_longbr'], [4, 'desc_word_luxuri'], [-4, 'desc_word_move-in'], [4, 'desc_word_ny'], [4, 'desc_word_offic'], [4, 'desc_word_onsit'], [4, 'desc_word_perfectli'], [-4, 'desc_word_photo'], [4, 'desc_word_prospect'], [-4, 'desc_word_rest'], [-4, 'desc_word_searchbr'], [-4, 'desc_word_solid'], [-4, 'desc_word_stop'], [4, 'desc_word_stroll'], [-4, 'desc_word_tabl'], [4, 'desc_word_theater'], [-4, 'desc_word_tremend'], [4, 'desc_word_truli'], [4, 'desc_word_world-class'], [-3, 'desc_word_456'], [-3, 'desc_word_70'], [3, 'desc_word_abund'], [3, 'desc_word_access'], [3, 'desc_word_accommod'], [-3, 'desc_word_ad'], [-3, 'desc_word_address'], [3, 'desc_word_bamboo'], [3, 'desc_word_bank'], [3, 'desc_word_baseboard'], [3, 'desc_word_bike'], [3, 'desc_word_bleached-plank'], [-3, 'desc_word_buildingbr'], [-3, 'desc_word_check'], [-3, 'desc_word_citybr'], [-3, 'desc_word_creat'], [-3, 'desc_word_day'], [-3, 'desc_word_dont'], [3, 'desc_word_doormanconcierg'], [3, 'desc_word_dream'], [-3, 'desc_word_dresser'], [-3, 'desc_word_east'], [3, 'desc_word_ft'], [-3, 'desc_word_game'], [3, 'desc_word_highli'], [-3, 'desc_word_includedbr'], [-3, 'desc_word_juli'], [-3, 'desc_word_kagglemanagerrenthopcompa'], [-3, 'desc_word_near'], [3, 'desc_word_nearli'], [3, 'desc_word_pictur'], [-3, 'desc_word_polish'], [-3, 'desc_word_realli'], [-3, 'desc_word_rent'], [3, 'desc_word_roombr'], [3, 'desc_word_schedul'], [-3, 'desc_word_sever'], [3, 'desc_word_special'], [3, 'desc_word_squar'], [3, 'desc_word_st'], [3, 'desc_word_staff'], [-3, 'desc_word_stove'], [-3, 'desc_word_time'], [-3, 'desc_word_unitsbr'], [-3, 'desc_word_use'], [3, 'desc_word_villag'], [-3, 'desc_word_wi-fi'], [3, 'desc_word_yard'], [-3, 'desc_word_zack'], [-2, 'desc_word_24-hour'], [2, 'desc_word_449-593-7152'], [2, 'desc_word_amen'], [-2, 'desc_word_andor'], [-2, 'desc_word_arrang'], [-2, 'desc_word_backsplash'], [2, 'desc_word_barbecu'], [-2, 'desc_word_bathroombr'], [-2, 'desc_word_beam'], [2, 'desc_word_broadway'], [-2, 'desc_word_caesarston'], [-2, 'desc_word_circl'], [2, 'desc_word_corner'], [-2, 'desc_word_daili'], [-2, 'desc_word_exactli'], [2, 'desc_word_fort'], [-2, 'desc_word_garden'], [2, 'desc_word_green'], [2, 'desc_word_grill'], [2, 'desc_word_half'], [2, 'desc_word_id'], [2, 'desc_word_import'], [2, 'desc_word_italian'], [-2, 'desc_word_john'], [-2, 'desc_word_know'], [2, 'desc_word_lifestyl'], [-2, 'desc_word_limit'], [-2, 'desc_word_m15'], [2, 'desc_word_manhattan'], [-2, 'desc_word_marbl'], [2, 'desc_word_mark'], [2, 'desc_word_medicin'], [-2, 'desc_word_nice'], [-2, 'desc_word_nightlif'], [-2, 'desc_word_plu'], [-2, 'desc_word_run'], [-2, 'desc_word_school'], [-2, 'desc_word_skylin'], [-2, 'desc_word_someth'], [2, 'desc_word_state-of-the-art'], [2, 'desc_word_stress'], [2, 'desc_word_stun'], [2, 'desc_word_swim'], [2, 'desc_word_ue'], [2, 'desc_word_vibrant'], [-2, 'desc_word_video'], [2, 'desc_word_viewingbr'], [-2, 'desc_word_wooden'], [1, 'desc_word_170-304-7893'], [1, 'desc_word_art'], [1, 'desc_word_breakfast'], [1, 'desc_word_bring'], [-1, 'desc_word_cabl'], [1, 'desc_word_cater'], [1, 'desc_word_chelsea'], [-1, 'desc_word_commut'], [1, 'desc_word_couch'], [-1, 'desc_word_cozi'], [-1, 'desc_word_current'], [-1, 'desc_word_dog'], [1, 'desc_word_easier'], [1, 'desc_word_eateri'], [1, 'desc_word_equip'], [-1, 'desc_word_exquisit'], [-1, 'desc_word_food'], [1, 'desc_word_forward'], [-1, 'desc_word_full-siz'], [1, 'desc_word_help'], [1, 'desc_word_high-end'], [-1, 'desc_word_histor'], [1, 'desc_word_homebr'], [-1, 'desc_word_intend'], [-1, 'desc_word_just'], [-1, 'desc_word_line'], [-1, 'desc_word_morebr'], [1, 'desc_word_night'], [1, 'desc_word_pharmaci'], [1, 'desc_word_plank'], [1, 'desc_word_quartz'], [-1, 'desc_word_quick'], [-1, 'desc_word_rare'], [1, 'desc_word_resid'], [-1, 'desc_word_river'], [1, 'desc_word_shade'], [1, 'desc_word_situat'], [-1, 'desc_word_soon'], [1, 'desc_word_sport'], [-1, 'desc_word_univers'], [-1, 'desc_word_way'], [1, 'desc_word_yoga'], [0, 'desc_word_4th'], [0, 'desc_word_absolut'], [0, 'desc_word_amaz'], [0, 'desc_word_apartmentbr'], [0, 'desc_word_appliances-'], [0, 'desc_word_apt'], [0, 'desc_word_base'], [0, 'desc_word_basement'], [0, 'desc_word_ceram'], [0, 'desc_word_counter-top'], [0, 'desc_word_desir'], [0, 'desc_word_flood'], [0, 'desc_word_heart'], [0, 'desc_word_hottest'], [0, 'desc_word_patio'], [0, 'desc_word_premium'], [0, 'desc_word_quickli'], [0, 'desc_word_readi'], [0, 'desc_word_spaciou'], [0, 'desc_word_standard'], [0, 'desc_word_strip'], [0, 'desc_word_supermarket'], [0, 'desc_word_tour'], [0, 'desc_word_upper'], [0, 'desc_word_war'], [0, 'desc_word_wifi']]\n"
     ]
    }
   ],
   "source": [
    "print_coefficients_info(lr_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2103f1",
   "metadata": {},
   "source": [
    "We can see that many of the columns have very large coefficients. Combined with the high training score and the low test score, this likely means there is overfitting, probably on the description words and the zip codes. Let's try to tune which columns we keep from those sets of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25fcfec",
   "metadata": {},
   "source": [
    "Let's drop some of the created columns since they aren't needed besides created_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0450ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_cols_to_drop = [\"created_epoch_secs\", \"created_year\"]\n",
    "X_train = X_train.drop(columns=more_cols_to_drop)\n",
    "X_test = X_test.drop(columns=more_cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb59963",
   "metadata": {},
   "source": [
    "Let's remove any description words that show up less often. Through inspection of some of the high impact words and descriptions, we can see that some of the words are due to the syntax of the descriptions rather than something to do with the pricing of the apartment, so it is likely we are overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4fc40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_counts = X_train.filter(like=\"desc_word_\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b771a",
   "metadata": {},
   "source": [
    "It looks like some of the zip code coefficients are very high. We probably do not have enough data on zip codes to train a model with them, but they might have high impact on the price. Let's try dropping all zip codes under a certain threshold as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a722176",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_counts = X_train.filter(like=\"zipcode_\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c94d8a14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# possible pairings of desc_count thresholds and zipcode_count_thresholds to try\n",
    "# the first element is the number of listings that have the description\n",
    "# the second element is the number of listings that have the zipcode\n",
    "\n",
    "# Note that I have attempted a lot more combinations, but you may only be able\n",
    "# to run a few combinations in one session due to memory issues\n",
    "\n",
    "# desc_count_thresholds = [0, 500, 1000, 1500, 2000, 3000, 5000]\n",
    "# zipcode_count_thresholds = [0, 10, 15, 20, 50, 80, 100, 200]\n",
    "\n",
    "desc_count_thresholds = [500, 1000, 1500, 2000]\n",
    "zipcode_count_thresholds = [10, 15, 20]\n",
    "\n",
    "new_train_datas = {}\n",
    "\n",
    "for desc_count_threshold in desc_count_thresholds:\n",
    "    for zipcode_count_threshold in zipcode_count_thresholds:\n",
    "        new_train = X_train\n",
    "        low_count_words = desc_counts[desc_counts < desc_count_threshold].index\n",
    "        low_count_words.array\n",
    "        new_train = new_train.drop(columns=low_count_words)\n",
    "\n",
    "        low_pop_zipcodes = zipcode_counts[zipcode_counts < zipcode_count_threshold].index\n",
    "        low_pop_zipcodes.array\n",
    "\n",
    "        new_train = new_train.drop(columns=low_pop_zipcodes)\n",
    "        new_train_datas[\"%s_%s\" % (desc_count_threshold, zipcode_count_threshold)] = new_train\n",
    "        \n",
    "len(new_train_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2fa97",
   "metadata": {},
   "source": [
    "Now let's try the linear regression again with each of the new_train_data sets. We have to scale again first each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae8a234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for: 500 10\n",
      "Train score: 0.7073569367332089\n",
      "Validation score: -8.237930382726495e+19\n",
      "for: 500 15\n",
      "Train score: 0.7055387038308188\n",
      "Validation score: -9.766340340223418e+18\n",
      "for: 500 20\n",
      "Train score: 0.7267503387769649\n",
      "Validation score: -8.437711573055596e+19\n",
      "for: 1000 10\n",
      "Train score: 0.6928735094991152\n",
      "Validation score: 0.6833618147570395\n",
      "for: 1000 15\n",
      "Train score: 0.6994677288576368\n",
      "Validation score: 0.6764556000198035\n",
      "for: 1000 20\n",
      "Train score: 0.6977593377691005\n",
      "Validation score: 0.6783224567364514\n",
      "for: 1500 10\n",
      "Train score: 0.6903237148839743\n",
      "Validation score: -1.1359111374837614e+20\n",
      "for: 1500 15\n",
      "Train score: 0.6830237284758895\n",
      "Validation score: -3.5732884301223405e+17\n",
      "for: 1500 20\n",
      "Train score: 0.6766823043586001\n",
      "Validation score: 0.6747534268262652\n",
      "for: 2000 10\n",
      "Train score: 0.676127946922569\n",
      "Validation score: 0.6726571168777167\n",
      "for: 2000 15\n",
      "Train score: 0.6927222397886315\n",
      "Validation score: 0.6573738671622624\n",
      "for: 2000 20\n",
      "Train score: 0.6791948034617337\n",
      "Validation score: 0.6692736146010719\n"
     ]
    }
   ],
   "source": [
    "for desc_count_threshold in desc_count_thresholds:\n",
    "    for zipcode_count_threshold in zipcode_count_thresholds:\n",
    "        new_train = new_train_datas[\"%s_%s\" % (desc_count_threshold, zipcode_count_threshold)]\n",
    "        new_train_sm, new_valid, Y_new_train_sm, Y_new_valid = train_test_split(new_train, Y_train, test_size=0.5)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # fitting the scaler to the training data and then also transforming the validation and test data\n",
    "        new_train_scaled = scaler.fit_transform(new_train_sm)\n",
    "\n",
    "        # transform the test data without fitting (only fit on the train data)\n",
    "        new_valid_scaled = scaler.transform(new_valid)\n",
    "        \n",
    "        new_lr = LinearRegression()\n",
    " \n",
    "        # Fit the model to the training data only\n",
    "        new_lr.fit(new_train_scaled, Y_new_train_sm)\n",
    "\n",
    "        # scoring the train and test set\n",
    "        print(f'for: {desc_count_threshold} {zipcode_count_threshold}')\n",
    "        print(f'Train score: {new_lr.score(new_train_scaled, Y_new_train_sm)}')\n",
    "        print(f'Validation score: {new_lr.score(new_valid_scaled, Y_new_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42df7ac",
   "metadata": {},
   "source": [
    "We can see that the model performs relatively closely when we remove description words that occur less than 2000 times and zip codes that occur less than 15 times. Through some other trial and error, we choose these to be the thresholds - although on some runs depending on the training set different hyperparameters may be better, it seems like below 2000 sometimes there is a large drop in score. Let's remove the columns from all the original sets of data now.\n",
    "\n",
    "We will create a new validation set and scale again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc407c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_count_words = desc_counts[desc_counts < 2000].index\n",
    "low_count_words.array\n",
    "low_pop_zipcodes = zipcode_counts[zipcode_counts < 15].index\n",
    "low_pop_zipcodes.array\n",
    "\n",
    "X_train = X_train.drop(columns=low_count_words)\n",
    "X_train = X_train.drop(columns=low_pop_zipcodes)\n",
    "X_test = X_test.drop(columns=low_count_words)\n",
    "X_test = X_test.drop(columns=low_pop_zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7ec0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, X_valid, Y_train_sm, Y_valid = train_test_split(X_train, Y_train, test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fitting the scaler to the training data and then also transforming the validation and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train_sm)\n",
    "\n",
    "# transform the test data without fitting (only fit on the train data)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a38a9c",
   "metadata": {},
   "source": [
    "After tuning which columns we remove, we have a reasonable model, but it is still not that good. Let's see if we can improve it by tuning other hyper parameters. Linear regressions don't have that many parameters so this might not help that much.\n",
    "\n",
    "The hyper parameter tuning will do a 5 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fae8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False],\n",
    "    'copy_X': [True, False]\n",
    "}\n",
    " \n",
    "grid = GridSearchCV(lr_model, params, cv=5)\n",
    " \n",
    "grid.fit(X_train_scaled, Y_train_sm)\n",
    " \n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be956a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.67380441388275\n",
      "Validation score: 0.6748891355428662\n"
     ]
    }
   ],
   "source": [
    "# instantiate a new model with the best parameters\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
    " \n",
    "# Fit the model to the training data only\n",
    "lr_model.fit(X_train_scaled, Y_train_sm)\n",
    "\n",
    "lr_y_pred = lr_model.predict(X_valid_scaled)\n",
    " \n",
    "# scoring the train and test set\n",
    "print(f'Train score: {lr_model.score(X_train_scaled, Y_train_sm)}')\n",
    "print(f'Validation score: {lr_model.score(X_valid_scaled, Y_valid)}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52f8560d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1427154.331623955\n",
      "RMSE: 1194.63564806344\n",
      "MAE: 700.8383135897212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculating the MSE\n",
    "print(f'MSE: {mse(Y_valid, lr_y_pred)}')\n",
    "\n",
    "# calculating the RMSE\n",
    "print(f'RMSE: {np.sqrt(mse(Y_valid, lr_y_pred))}')\n",
    " \n",
    "# calculating the MAE\n",
    "print(f'MAE: {np.mean(np.abs(Y_valid - lr_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d122ed",
   "metadata": {},
   "source": [
    "Let's inspect the model to see how different factors might impact rental price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa16881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364,)\n",
      "[[977, 'bathrooms'], [643, 'bedrooms'], [402, 'zipcode_10011'], [341, 'zipcode_10012'], [320, 'zipcode_10003'], [292, 'zipcode_10009'], [271, 'zipcode_10028'], [265, 'zipcode_10017'], [263, 'zipcode_10023'], [262, 'zipcode_10001'], [251, 'zipcode_10019'], [244, 'zipcode_10021'], [243, 'zipcode_10014'], [228, 'zipcode_10065'], [225, 'zipcode_10018'], [223, 'doorman'], [220, 'zipcode_10016'], [214, 'zipcode_10002'], [208, 'zipcode_10044'], [205, 'zipcode_10162'], [201, 'zipcode_10199'], [189, 'zipcode_10022'], [-177, 'desc_word_support'], [170, 'zipcode_10013'], [159, 'zipcode_10007'], [159, 'zipcode_10271'], [157, 'zipcode_10069'], [137, 'zipcode_10025'], [134, 'zipcode_10005'], [132, 'zipcode_10006'], [-132, 'desc_word_flex'], [121, 'zipcode_10282'], [119, 'desc_word_estat'], [118, 'zipcode_10154'], [116, 'zipcode_10103'], [114, 'laundry_in_unit'], [114, 'zipcode_10278'], [108, 'zipcode_11201'], [107, 'zipcode_10038'], [104, 'zipcode_10171'], [103, 'zipcode_10280'], [98, 'zipcode_11211'], [-95, 'hardwood_floors'], [93, 'fitness_center'], [-89, 'desc_word_convert'], [89, 'desc_word_equal'], [86, 'desc_word_separ'], [86, 'desc_word_york'], [-81, 'subway_distance_max_4000'], [72, 'desc_word_servic'], [71, 'zipcode_10153'], [70, 'zipcode_10110'], [67, 'dogs_allowed'], [67, 'zipcode_10020'], [65, 'desc_word_exposur'], [64, 'zipcode_10167'], [-64, 'desc_word_new'], [-63, 'desc_word_contact'], [62, 'zipcode_10029'], [62, 'desc_word_terrac'], [61, 'desc_word_dine'], [60, 'zipcode_11217'], [60, 'desc_word_central'], [60, 'desc_word_custom'], [-60, 'desc_word_opportunitypa'], [-59, 'cats_allowed'], [59, 'desc_word_home'], [56, 'desc_word_open'], [53, 'dining_room'], [52, 'zipcode_11109'], [-52, 'desc_word_brick'], [50, 'terrace'], [50, 'desc_word_dryer'], [48, 'elevator'], [-48, 'outdoor_space'], [47, 'zipcode_10026'], [47, 'desc_word_ceil'], [46, 'desc_word_elev'], [-45, 'high_speed_internet'], [45, 'desc_word_expos'], [-44, 'desc_word_deal'], [42, 'desc_word_like'], [-42, 'desc_word_price'], [-42, 'desc_word_text'], [-41, 'desc_word_midtown'], [40, 'zipcode_10119'], [40, 'zipcode_11215'], [40, 'zipcode_11231'], [39, 'longitude'], [39, 'zipcode_10027'], [-39, 'desc_word_center'], [-39, 'desc_word_hour'], [-38, 'new_construction'], [38, 'desc_word_finish'], [38, 'desc_word_washerdry'], [37, 'wheelchair_access'], [37, 'desc_word_exclus'], [37, 'desc_word_washer'], [36, 'loft'], [-36, 'desc_word_laundri'], [36, 'desc_word_room'], [35, 'desc_word_art'], [-34, 'desc_word_dishwash'], [-34, 'desc_word_everi'], [-34, 'desc_word_hardwood'], [34, 'desc_word_onli'], [-34, 'desc_word_tile'], [-34, 'desc_word_true'], [33, 'zipcode_11238'], [33, 'desc_word_applianc'], [33, 'desc_word_brand'], [33, 'desc_word_deck'], [32, 'desc_word_fulli'], [31, 'zipcode_11205'], [31, 'zipcode_11222'], [31, 'desc_word_avenu'], [-31, 'desc_word_queen'], [30, 'zipcode_11106'], [30, 'desc_word_east'], [-30, 'desc_word_locat'], [-30, 'desc_word_neighborhood'], [-30, 'desc_word_pa'], [-30, 'desc_word_real'], [-29, 'zipcode_11233'], [-29, 'desc_word_kagglemanagerrenthopcom'], [-29, 'desc_word_perfect'], [-28, 'zipcode_10463'], [-28, 'desc_word_ani'], [-28, 'desc_word_stainless'], [-28, 'desc_word_sunni'], [-27, 'no_fee'], [27, 'zipcode_11104'], [27, 'desc_word_24'], [-27, 'desc_word_free'], [-27, 'desc_word_great'], [-26, 'desc_word_renov'], [25, 'desc_word_appoint'], [-25, 'desc_word_bright'], [-25, 'desc_word_conveni'], [25, 'desc_word_modern'], [25, 'desc_word_offer'], [25, 'desc_word_pleas'], [25, 'desc_word_stun'], [24, 'zipcode_10030'], [-24, 'desc_word_calltext'], [-24, 'desc_word_concierg'], [24, 'desc_word_park'], [24, 'desc_word_privat'], [-24, 'desc_word_properti'], [-24, 'desc_word_size'], [-24, 'desc_word_transport'], [23, 'zipcode_11102'], [-23, 'desc_word_clean'], [-23, 'desc_word_nyc'], [-23, 'desc_word_valet'], [-23, 'desc_word_walk'], [22, 'latitude'], [22, 'desc_word_complet'], [22, 'desc_word_garden'], [22, 'desc_word_href'], [-22, 'desc_word_on-sit'], [21, 'dishwasher'], [-21, 'pre-war'], [-21, 'zipcode_11237'], [-21, 'desc_word_access'], [-21, 'desc_word_area'], [-21, 'desc_word_block'], [-21, 'desc_word_gym'], [-21, 'desc_word_high'], [21, 'desc_word_manhattan'], [-21, 'desc_word_massiv'], [20, 'created_day'], [-20, 'desc_word_cabinetri'], [-20, 'desc_word_close'], [-20, 'desc_word_enjoy'], [-20, 'desc_word_step'], [20, 'desc_word_white'], [19, 'desc_word_hous'], [-18, 'balcony'], [-18, 'zipcode_11374'], [-18, 'desc_word_amaz'], [-18, 'desc_word_bond'], [-18, 'desc_word_countertop'], [18, 'desc_word_floor'], [18, 'desc_word_need'], [18, 'desc_word_pool'], [-18, 'desc_word_studio'], [-17, 'zipcode_11213'], [-17, 'desc_word_closet'], [-17, 'desc_word_featur'], [-17, 'desc_word_fit'], [-17, 'desc_word_kitchen'], [-17, 'desc_word_near'], [17, 'desc_word_short'], [-17, 'desc_word_station'], [-16, 'desc_word_away'], [-16, 'desc_word_light'], [-16, 'desc_word_loung'], [16, 'desc_word_restaur'], [-16, 'desc_word_set'], [-16, 'desc_word_super'], [15, 'zipcode_10035'], [-15, 'zipcode_10458'], [-15, 'desc_word_broker'], [15, 'desc_word_build'], [-15, 'desc_word_email'], [15, 'desc_word_gorgeou'], [-15, 'desc_word_immedi'], [-15, 'desc_word_includ'], [-15, 'desc_word_place'], [-15, 'desc_word_spaciou'], [15, 'desc_word_target_blank'], [-15, 'desc_word_wall'], [14, 'zipcode_11101'], [14, 'desc_word_addit'], [-14, 'desc_word_apart'], [-14, 'desc_word_club'], [-14, 'desc_word_just'], [-14, 'desc_word_make'], [-14, 'desc_word_market'], [14, 'desc_word_thi'], [-14, 'desc_word_ton'], [14, 'desc_word_window'], [13, 'zipcode_07310'], [13, 'desc_word_ha'], [13, 'desc_word_inform'], [-13, 'desc_word_train'], [13, 'desc_word_wood'], [-12, 'roof_deck'], [12, 'zipcode_11372'], [-12, 'desc_word_huge'], [12, 'desc_word_live'], [12, 'desc_word_lobbi'], [12, 'desc_word_schedul'], [-11, 'common_outdoor_space'], [11, 'zipcode_11209'], [-11, 'zipcode_11210'], [-11, 'desc_word_counter'], [11, 'desc_word_design'], [11, 'desc_word_heat'], [-11, 'desc_word_larg'], [-11, 'desc_word_love'], [-11, 'desc_word_mani'], [11, 'desc_word_marbl'], [-11, 'desc_word_outdoor'], [-11, 'desc_word_roof'], [-11, 'desc_word_villag'], [-10, 'desc_word_kagglemanagerrenthopcombr'], [-10, 'desc_word_natur'], [10, 'desc_word_newli'], [-10, 'desc_word_pet'], [-10, 'desc_word_right'], [10, 'desc_word_space'], [-10, 'desc_word_storag'], [10, 'desc_word_time'], [-10, 'desc_word_updat'], [-10, 'desc_word_upper'], [10, 'desc_word_view'], [-9, 'zipcode_10467'], [9, 'zipcode_11368'], [-9, 'zipcode_11415'], [-9, 'desc_word_bed'], [9, 'desc_word_bike'], [-9, 'desc_word_cafe'], [-9, 'desc_word_come'], [-9, 'desc_word_friendli'], [9, 'desc_word_month'], [9, 'desc_word_rental'], [9, 'desc_word_resid'], [-9, 'desc_word_unit'], [-8, 'zipcode_10031'], [-8, 'desc_word_24-hour'], [-8, 'desc_word_allow'], [8, 'desc_word_avail'], [8, 'desc_word_beauti'], [-8, 'desc_word_cabinet'], [8, 'desc_word_entertain'], [8, 'desc_word_help'], [-8, 'desc_word_hill'], [-8, 'desc_word_layout'], [8, 'desc_word_luxuri'], [-7, 'zipcode_10034'], [-7, 'zipcode_10452'], [-7, 'zipcode_11204'], [-7, 'zipcode_11226'], [7, 'zipcode_11377'], [7, 'desc_word_balconi'], [-7, 'desc_word_bedroom'], [7, 'desc_word_district'], [-7, 'desc_word_king'], [-7, 'desc_word_subway'], [-7, 'desc_word_sun'], [-6, 'zipcode_11206'], [6, 'zipcode_11216'], [-6, 'zipcode_11223'], [6, 'zipcode_11354'], [-6, 'zipcode_11435'], [-6, 'desc_word_fee'], [6, 'desc_word_river'], [6, 'desc_word_squar'], [-6, 'desc_word_street'], [-5, 'zipcode_10468'], [5, 'zipcode_11103'], [5, 'zipcode_11220'], [5, 'zipcode_11221'], [5, 'desc_word_amen'], [5, 'desc_word_citi'], [-5, 'desc_word_easi'], [5, 'desc_word_look'], [5, 'desc_word_oak'], [5, 'desc_word_steel'], [5, 'desc_word_veri'], [4, 'swimming_pool'], [4, 'garden_patio'], [4, 'zipcode_11203'], [4, 'zipcode_11235'], [4, 'zipcode_11421'], [-4, 'desc_word_bath'], [-4, 'desc_word_line'], [4, 'desc_word_microwav'], [-4, 'desc_word_prime'], [4, 'desc_word_rent'], [-4, 'desc_word_shop'], [-3, 'zipcode_10039'], [3, 'zipcode_11218'], [-3, 'zipcode_11225'], [3, 'zipcode_11351'], [-3, 'zipcode_11367'], [-3, 'zipcode_11385'], [3, 'very_far_from_subway'], [-3, 'desc_word_bathroom'], [3, 'desc_word_corner'], [-3, 'desc_word_gut'], [2, 'zipcode_11373'], [2, 'desc_word_amp'], [-2, 'desc_word_doorman'], [2, 'desc_word_equip'], [-2, 'desc_word_facil'], [-2, 'desc_word_garag'], [-2, 'desc_word_heart'], [-2, 'desc_word_landscap'], [-2, 'desc_word_plenti'], [-2, 'desc_word_rooftop'], [2, 'desc_word_store'], [2, 'desc_word_water'], [-1, 'zipcode_10032'], [1, 'zipcode_11105'], [-1, 'zipcode_11219'], [1, 'desc_word_bar'], [-1, 'desc_word_feel'], [1, 'desc_word_list'], [-1, 'desc_word_lot'], [1, 'desc_word_minut'], [1, 'desc_word_west'], [0, 'exclusive'], [0, 'zipcode_10037'], [0, 'zipcode_11230'], [0, 'zipcode_11375'], [0, 'desc_word_ave'], [0, 'desc_word_best'], [0, 'desc_word_granit'], [0, 'desc_word_quiet'], [0, 'desc_word_st'], [0, 'desc_word_today']]\n"
     ]
    }
   ],
   "source": [
    "print_coefficients_info(lr_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbec555",
   "metadata": {},
   "source": [
    "### Logistic Regression or KNN\n",
    "\n",
    "This is not a classification problem so a logistic regression or KNN likely won't be very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536357a",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "The random forest may be a suitable model for rental prices because decision trees are similar to how customers may make decisions and hence set the market.\n",
    "\n",
    "Here, we do not need to use the scaled data, so we can use X_train directly. We will use X_train_sm for now to avoid using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a13e90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "rf_model = RandomForestRegressor(n_jobs=-1, random_state=1)\n",
    " \n",
    "# Fit the model to the training data only\n",
    "rf_model.fit(X_train_sm, Y_train_sm)\n",
    "\n",
    "rf_y_pred = rf_model.predict(X_valid)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcbf33ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9744166860101235\n",
      "Validation score: 0.8266172930801319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# scoring the train and test set\n",
    "print(f'Train score: {rf_model.score(X_train_sm, Y_train_sm)}')\n",
    "print(f'Validation score: {rf_model.score(X_valid, Y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "797f2c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 761106.1587331304\n",
      "RMSE: 872.4139835726675\n",
      "MAE: 426.63538385783556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculating the MSE\n",
    "print(f'MSE: {mse(Y_valid, rf_y_pred)}')\n",
    "\n",
    "# calculating the RMSE\n",
    "print(f'RMSE: {np.sqrt(mse(Y_valid, rf_y_pred))}')\n",
    " \n",
    "# calculating the MAE\n",
    "print(f'MAE: {np.mean(np.abs(Y_valid - rf_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6434825",
   "metadata": {},
   "source": [
    "We can see the Random Forest Regressor out performs the linear regression. It has some overfitting. We can tune the hyper parameters even further to try to improve it. Here, we will try a 3-fold and try a grid of different hyper parameters. We choose specifically low number of options and 3-fold instead of the standard 5-fold here to improve run time, but you may try different options to land on the optimal ones.\n",
    "\n",
    "We can run this on the original X_train because it will generate the validation sets out of that set, hence we do not overfit before looking at the performance on the test set which has not been used to fit anything yet. We don't need to use X_train_sm since it will create the validation set for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb251a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous runs showed 500, 50 was a good set of parameters\n"
     ]
    }
   ],
   "source": [
    "# 200, 300 and 20, 30 => 300, 30\n",
    "# 300, 500 and 30, 50 => 500, 50\n",
    "# creating a dictionary of hyperparameters\n",
    "params = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [30, 50]\n",
    "}\n",
    "    \n",
    "# instantiating the grid search\n",
    "grid = GridSearchCV(rf_model, params, cv=3)\n",
    " \n",
    "# fitting the grid search\n",
    "grid.fit(X_train, Y_train)\n",
    " \n",
    "# the best parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb94ff",
   "metadata": {},
   "source": [
    "For random forest, typically the higher the number of estimators and max depth, the better, although it may lead to overfitting. However, the higher these values, the longer the model may take to run. Because of limited compute power, we weren't able to test above 500 estimators and 50 depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd753edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9748450328963889\n",
      "Validation score: 0.8299247735167214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=1\n",
    ")\n",
    " \n",
    "# Fit the model to the training data only\n",
    "rf_model.fit(X_train_sm, Y_train_sm)\n",
    "\n",
    "rf_y_pred = rf_model.predict(X_valid)\n",
    "\n",
    "# scoring the train and test set\n",
    "print(f'Train score: {rf_model.score(X_train_sm, Y_train_sm)}')\n",
    "print(f'Validation score: {rf_model.score(X_valid, Y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e90ae308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 746587.1575311183\n",
      "RMSE: 864.0527515905023\n",
      "MAE: 423.5105148359923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculating the MSE\n",
    "print(f'MSE: {mse(Y_valid, rf_y_pred)}')\n",
    "\n",
    "# calculating the RMSE\n",
    "print(f'RMSE: {np.sqrt(mse(Y_valid, rf_y_pred))}')\n",
    " \n",
    "# calculating the MAE\n",
    "print(f'MAE: {np.mean(np.abs(Y_valid - rf_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3537c",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost is the extreme gradient boosting model. It uses decision trees similar to random forest, but then the models under each decision tree are further boosted by combining models together to form a stronger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38ea52ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9458181969078618\n",
      "Validation score: 0.8377872328719473\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    " \n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# fitting the model to the training set\n",
    "xgb.fit(X_train_sm, Y_train_sm)\n",
    " \n",
    "# predicting on the validation set\n",
    "xgb_y_pred = xgb.predict(X_valid)\n",
    "\n",
    "print(f'Train score: {xgb.score(X_train_sm, Y_train_sm)}')\n",
    "print(f'Validation score: {xgb.score(X_valid, Y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b074cd16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 712072.9528312399\n",
      "RMSE: 843.8441519802338\n",
      "MAE: 458.932559217873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# calculating the MSE\n",
    "print(f'MSE: {mse(Y_valid, xgb_y_pred)}')\n",
    "\n",
    "# calculating the RMSE\n",
    "print(f'RMSE: {np.sqrt(mse(Y_valid, xgb_y_pred))}')\n",
    " \n",
    "# calculating the MAE\n",
    "print(f'MAE: {np.mean(np.abs(Y_valid - xgb_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582bc7a",
   "metadata": {},
   "source": [
    "Let's try some different hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03b35cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.25, 'max_depth': 8, 'n_estimators': 500}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'learning_rate': [0.25],\n",
    "    'max_depth': [2, 8]\n",
    "}\n",
    "    \n",
    "grid = GridSearchCV(xgb, params, cv=3)\n",
    " \n",
    "grid.fit(X_train, Y_train)\n",
    " \n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b71b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9978851963174936\n",
      "Validation score: 0.8519405820805195\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=500, \n",
    "    learning_rate=0.25,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "# fitting the model to the training data\n",
    "xgb.fit(X_train_sm, Y_train_sm)\n",
    " \n",
    "# predicting on the test set\n",
    "xgb_y_pred = xgb.predict(X_valid)\n",
    "\n",
    "# scoring the train and test set\n",
    "print(f'Train score: {xgb.score(X_train_sm, Y_train_sm)}')\n",
    "print(f'Validation score: {xgb.score(X_valid, Y_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22f45def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 649943.3354044943\n",
      "RMSE: 806.1906321736158\n",
      "MAE: 404.2215803125705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# calculating the MSE\n",
    "print(f'MSE: {mse(Y_valid, xgb_y_pred)}')\n",
    "\n",
    "# calculating the RMSE\n",
    "print(f'RMSE: {np.sqrt(mse(Y_valid, xgb_y_pred))}')\n",
    " \n",
    "# calculating the MAE\n",
    "print(f'MAE: {np.mean(np.abs(Y_valid - xgb_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e196f7",
   "metadata": {},
   "source": [
    "We might be able to tune the hyper parameters some more, but we see that the train score is close to 1 while the validation score is not at that level. This indicates overfitting which may not be improved greatly by further hyper parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad3f1c",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "Our best model is the XGBoost model. This makes sense since price may involve decision trees, and the XGBoost model improves on random forest by combining weak models.\n",
    "\n",
    "Let's see how it performs against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "255e4a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8044522584560098\n",
      "MSE: 892357.8965946656\n",
      "RMSE: 944.6469692931141\n",
      "MAE: 417.72910687594464\n"
     ]
    }
   ],
   "source": [
    "print(f'Test score: {xgb.score(X_test, Y_test)}')\n",
    "\n",
    "xgb_test_y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(f'MSE: {mse(Y_test, xgb_test_y_pred)}')\n",
    "print(f'RMSE: {np.sqrt(mse(Y_test, xgb_test_y_pred))}')\n",
    "print(f'MAE: {np.mean(np.abs(Y_test - xgb_test_y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d12e01",
   "metadata": {},
   "source": [
    "As expected, it does a bit worse than the validation set.\n",
    "Let's save the model so others can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07310a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa0b1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb, open('nyc_rental_price.pkl','wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695d8bb",
   "metadata": {},
   "source": [
    "Here we can load the saved model and predict a price with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d93c4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pickle.load(open('nyc_rental_price.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5d5f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price: 4259.35\n",
      "Actual price: 4300\n"
     ]
    }
   ],
   "source": [
    "# predicting the price of a vehicle on input data\n",
    "print(f\"Predicted price: {saved_model.predict(X_test)[0]:.2f}\")\n",
    "print(f\"Actual price: {Y_test.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaece99",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "We can see by the MAE that the model is on average $400 off from the true rental price. Although we may try tuning the model and hyper parameters more, We are likely missing some key pieces of data for NYC rental properties to improve this much further - notably square footage. Likely followups would be to be smarter on grabbing this information from the description, or to find a way to add on more valuable data and then retune the data. A neural network properly tuned may also present some improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495160e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
